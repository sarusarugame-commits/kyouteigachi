import requests
from bs4 import BeautifulSoup
import time
import re
import unicodedata
import random
from requests.adapters import HTTPAdapter
from urllib3.util import Retry

# ==========================================
# âš™ï¸ è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
MAX_RETRIES = 3        # ãƒªãƒˆãƒ©ã‚¤å›æ•°
UA_LIST = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0"
]

def clean_text(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã®ä¸è¦ãªç©ºç™½ã‚„æ”¹è¡Œã‚’å‰Šé™¤"""
    if not text: return ""
    text = unicodedata.normalize('NFKC', str(text))
    return text.replace("\n", "").replace("\r", "").replace("Â¥", "").replace(",", "").strip()

def extract_float(text):
    """
    ã€é‡è¦ã€‘ã‚ã‚‰ã‚†ã‚‹æ–‡å­—åˆ—ã‹ã‚‰æ•°å€¤ã ã‘ã‚’æŠœãå‡ºã™é–¢æ•°
    '8.0Â°C' -> 8.0
    'é¢¨é€Ÿ3m' -> 3.0
    'ST.12' -> 0.12
    """
    if not text: return 0.0
    cleaned = clean_text(text)
    # æ•°å­—ã¨ãƒ‰ãƒƒãƒˆ(.)ã®å¡Šã‚’æ¢ã™æ­£è¦è¡¨ç¾
    match = re.search(r"(\d+\.?\d*)", cleaned)
    if match:
        try:
            return float(match.group(1))
        except:
            return 0.0
    return 0.0

def get_session():
    """ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
    session = requests.Session()
    retries = Retry(total=MAX_RETRIES, backoff_factor=1, status_forcelist=[500, 502, 503, 504])
    adapter = HTTPAdapter(pool_connections=10, pool_maxsize=10, max_retries=retries)
    session.mount("https://", adapter)
    return session

def get_soup(session, url):
    """HTMLã‚’å–å¾—ã—ã¦BeautifulSoupã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™"""
    if session is None: session = get_session()
    for i in range(MAX_RETRIES):
        try:
            headers = {'User-Agent': random.choice(UA_LIST)}
            res = session.get(url, headers=headers, timeout=10)
            res.encoding = res.apparent_encoding
            
            if res.status_code == 200:
                # é–‹å‚¬ä¸­æ­¢ã‚„ãƒ‡ãƒ¼ã‚¿ãªã—ã®åˆ¤å®š
                if "ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“" in res.text or "é–‹å‚¬ä¸­æ­¢" in res.text:
                    return None
                return BeautifulSoup(res.text, 'html.parser')
            
            time.sleep(random.uniform(1, 2))
        except Exception:
            pass
    return None

def scrape_race_data(session, jcd, rno, date_str):
    """
    ãƒ¡ã‚¤ãƒ³ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°
    """
    base_url = "https://www.boatrace.jp/owpc/pc/race"
    
    # 1. ç›´å‰æƒ…å ±ï¼ˆé¢¨é€Ÿã€å±•ç¤ºã‚¿ã‚¤ãƒ ï¼‰
    soup_before = get_soup(session, f"{base_url}/beforeinfo?rno={rno}&jcd={jcd:02d}&hd={date_str}")
    if not soup_before: return None 

    # 2. ç•ªçµ„è¡¨ï¼ˆé¸æ‰‹ãƒ‡ãƒ¼ã‚¿ï¼‰
    soup_list = get_soup(session, f"{base_url}/racelist?rno={rno}&jcd={jcd:02d}&hd={date_str}")
    if not soup_list: return None

    # 3. çµæœãƒšãƒ¼ã‚¸ï¼ˆã‚ªãƒƒã‚ºå–å¾—ç”¨ãƒ»ãªãã¦ã‚‚é€²ã‚€ï¼‰
    soup_res = get_soup(session, f"{base_url}/raceresult?rno={rno}&jcd={jcd:02d}&hd={date_str}")

    row = {'date': date_str, 'jcd': jcd, 'rno': rno}

    # --- â‘  é¢¨é€Ÿã®å–å¾—ï¼ˆæ°—æ¸©ã¨é–“é•ãˆãªã„å‡¦ç†ï¼‰ ---
    try:
        # å¤©å€™ã‚¨ãƒªã‚¢ã®ãƒ‡ãƒ¼ã‚¿ã‚’å…¨å–å¾—
        weather_elems = soup_before.select(".weather1_bodyUnitLabelData")
        wind_val = 0.0
        
        # ä¸­èº«ã‚’ãƒ«ãƒ¼ãƒ—ã—ã¦ã€Œmã€ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‚‚ã®ï¼ˆã‹ã¤ã€Œcmã€=æ³¢é«˜ ã§ã¯ãªã„ã‚‚ã®ï¼‰ã‚’æ¢ã™
        for elem in weather_elems:
            txt = elem.text
            if "m" in txt and "cm" not in txt:
                wind_val = extract_float(txt)
                break
        
        row['wind'] = wind_val
    except:
        row['wind'] = 0.0

    # --- â‘¡ å„è‰‡ãƒ‡ãƒ¼ã‚¿ ---
    for i in range(1, 7):
        try:
            # A. å±•ç¤ºã‚¿ã‚¤ãƒ 
            boat_cell = soup_before.select_one(f".is-boatColor{i}")
            if boat_cell:
                tds = boat_cell.find_parent("tbody").select("td")
                # ä½•ç•ªç›®ã®ã‚«ãƒ©ãƒ ã«ã‚ã£ã¦ã‚‚ã€ã¨ã‚Šã‚ãˆãš5ç•ªç›®(index 4)ä»˜è¿‘ã‚’å–å¾—ã—ã¦æ•°å€¤åŒ–
                if len(tds) > 4:
                    row[f'ex{i}'] = extract_float(tds[4].text)
                else:
                    row[f'ex{i}'] = 6.80
            else:
                row[f'ex{i}'] = 6.80

            # B. ç•ªçµ„è¡¨ãƒ‡ãƒ¼ã‚¿
            list_elem = soup_list.select_one(f".is-boatColor{i}")
            if list_elem:
                tbody = list_elem.find_parent("tbody")
                tds_list = tbody.select("td")
                
                # å‹ç‡ (Usually index 3)
                row[f'wr{i}'] = extract_float(tds_list[3].text)
                
                # ãƒ•ãƒ©ã‚¤ãƒ³ã‚°æ•°
                row[f'f{i}'] = int(extract_float(tds_list[2].text))
                
                # ST (ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‹ã‚‰ "ST0.12" ã®ã‚ˆã†ãªå½¢ã‚’æ¢ã™)
                st_match = re.search(r"ST(\d\.\d{2})", clean_text(tbody.text))
                if st_match:
                    row[f'st{i}'] = float(st_match.group(1))
                else:
                    row[f'st{i}'] = 0.17 # å¹³å‡å€¤

                # ãƒ¢ãƒ¼ã‚¿ãƒ¼ (Usually index 5 or 6)
                mo_val = extract_float(tds_list[5].text)
                # ã‚‚ã—0.0ãªã‚‰ã€ã‚«ãƒ©ãƒ ã‚ºãƒ¬ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§éš£ã‚‚è¦‹ã‚‹
                if mo_val == 0.0 and len(tds_list) > 6:
                     mo_val = extract_float(tds_list[6].text)
                
                row[f'mo{i}'] = mo_val if mo_val > 0 else 30.0

            else:
                # ãƒ‡ãƒ¼ã‚¿ãªã—ã®å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                row[f'wr{i}'] = 5.0
                row[f'f{i}'] = 0
                row[f'st{i}'] = 0.17
                row[f'mo{i}'] = 30.0

        except Exception:
            # ä¸‡ãŒä¸€ã®ã‚¨ãƒ©ãƒ¼æ™‚ã¯å®‰å…¨ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            row[f'ex{i}'] = 6.80
            row[f'wr{i}'] = 5.0
            row[f'f{i}'] = 0
            row[f'st{i}'] = 0.17
            row[f'mo{i}'] = 30.0

    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆä»Šå›ã¯ä½¿ç”¨ã—ãªã„ãŒã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼é˜²æ­¢ã®ãŸã‚0ã§åŸ‹ã‚ã‚‹ï¼‰
    row['nirentan'] = 0
    row['sanrentan'] = 0
    row['tansho'] = 0
    
    # ã‚ªãƒƒã‚ºãŒã‚ã‚Œã°å–å¾—ï¼ˆextract_floatãŒå¼·åŠ›ãªã®ã§ãã®ã¾ã¾ä½¿ãˆã‚‹ï¼‰
    if soup_res:
        try:
            # ç°¡æ˜“ãƒ­ã‚¸ãƒƒã‚¯: å˜å‹ãªã©ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™ï¼ˆå®Ÿéš›ã«ã¯Botå´ã§äºˆæ¸¬ã«ã‚ªãƒƒã‚ºã‚’ä½¿ã‚ãªã„ãªã‚‰0ã§OKï¼‰
            pass 
        except: pass

    return row

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œç”¨
    print("ğŸ›  scraper.py ãƒãƒ‹ãƒ¥ã‚¢ãƒ«æ›´æ–°ç‰ˆ")
    from datetime import datetime
    s = get_session()
    today = datetime.now().strftime("%Y%m%d")
    # ãƒ†ã‚¹ãƒˆ: ä»Šæ—¥ã®æ—¥ä»˜ã§ã©ã“ã‹ã®ãƒ¬ãƒ¼ã‚¹ã‚’å–å¾—
    try:
        data = scrape_race_data(s, 1, 1, today)
        print(f"å–å¾—çµæœ: {data}")
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")
